{
  "model_id": "gpt2",
  "tokenizer_id": "gpt2",
  "vocab_size": 50257,
  "max_context": 1024,
  "params": {
    "k": 10,
    "p": 0.9,
    "context": 1024,
    "stride": null
  },
  "timestamp": 1756254703.923542
}